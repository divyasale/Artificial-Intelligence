{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e65e3b6b",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5c6413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc82f7d",
   "metadata": {},
   "source": [
    "### Convert Into Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a567619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a demo text for nlp using nltk. full form of nltk is natural language toolkit\n"
     ]
    }
   ],
   "source": [
    "text=\"This is a demo text for NLP using NLTK. Full form of NLTK is Natural Language Toolkit\"\n",
    "lower_text=text.lower()\n",
    "print(lower_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f828941",
   "metadata": {},
   "source": [
    "### Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c8cd0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a demo text for NLP using NLTK.', 'Full form of NLTK is Natural Language Toolkit']\n"
     ]
    }
   ],
   "source": [
    "text=\"This is a demo text for NLP using NLTK. Full form of NLTK is Natural Language Toolkit\"\n",
    "sent_tokens=nltk.sent_tokenize(text)\n",
    "print(sent_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce30572",
   "metadata": {},
   "source": [
    "### Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aada365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'demo', 'text', 'for', 'NLP', 'using', 'NLTK', '.', 'Full', 'form', 'of', 'NLTK', 'is', 'Natural', 'Language', 'Toolkit']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/divyasale/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "text=\"This is a demo text for NLP using NLTK. Full form of NLTK is Natural Language Toolkit\"\n",
    "word_tokens=nltk.word_tokenize(text)\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae7623",
   "metadata": {},
   "source": [
    "### Identifying Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d2f0061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'demo', 'text', 'NLP', 'using', 'NLTK', '.', 'Full', 'form', 'NLTK', 'Natural', 'Language', 'Toolkit']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopword=stopwords.words('english')\n",
    "text=\"This is a demo text for NLP using NLTK. Full form of NLTK is Natural Language Toolkit\"\n",
    "removing_stopwords=[word for word in word_tokens if word not in stopword]\n",
    "print(removing_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21c8512",
   "metadata": {},
   "source": [
    "### Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0ef40b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'dog', 'are', 'barking', 'outside', ',', 'Are', 'the', 'cat', 'in', 'the', 'garden', '?']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/divyasale/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#It is based on porter Stemming algorithms\n",
    "stopword=stopwords.words('english')\n",
    "wordnet_Lemmatizer=WordNetLemmatizer()\n",
    "text=\"the dogs are barking outside,Are the cats in the garden?\"\n",
    "word_tokens=nltk.word_tokenize(text)\n",
    "lemmatized_word=[wordnet_Lemmatizer.lemmatize(word) for word in word_tokens]\n",
    "print(lemmatized_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fbbda1",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33091e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'demo', 'text', 'for', 'nlp', 'use', 'nltk', '.', 'full', 'form', 'of', 'nltk', 'is', 'natur', 'languag', 'processor']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "#It is based on Porter stemming Algorithm\n",
    "stopword = stopwords.words('english')\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "text = \"This is demo text for NLP using NLTK. Full form of NLTK is natural language Processor\"\n",
    "word_tokens = nltk.word_tokenize(text)\n",
    "stemmed_word = [snowball_stemmer.stem(word) for word in word_tokens]\n",
    "print(stemmed_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a08e93c",
   "metadata": {},
   "source": [
    "### Get word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4685749e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('is', 2), ('nltk', 2), ('this', 1), ('demo', 1), ('text', 1)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n",
    "text = \"This is demo text for NLP using NLTK. Full form of NLTK is natural language Processor\"\n",
    "word = nltk.word_tokenize(text.lower())\n",
    "freq = FreqDist(word)\n",
    "print (freq.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc865957",
   "metadata": {},
   "source": [
    "### POS (Parts of Speech) tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bc6474e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/divyasale/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'DT'), ('dogs', 'NNS'), ('are', 'VBP'), ('barking', 'VBG'), ('outside', 'IN')]\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "import nltk\n",
    "text = \"the dogs are barking outside\"\n",
    "word = nltk.word_tokenize(text)\n",
    "pos_tag = nltk.pos_tag(word)\n",
    "print(pos_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e8faeb",
   "metadata": {},
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66613b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/divyasale/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/divyasale/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barrack Obama']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "text = \"Who is Barrack Obama\"\n",
    "word = nltk.word_tokenize(text)\n",
    "pos_tag = nltk.pos_tag(word)\n",
    "chunk = nltk.ne_chunk(pos_tag)\n",
    "NE = [\" \".join(w for w, t in ele) for ele in chunk if isinstance(ele, nltk.Tree) ]\n",
    "print(NE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536aa02a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
